---
title: "practical_exercise_7 , Methods 3, 2021, autumn semester"
author: '[FILL IN YOUR NAME]'
date: "[FILL IN THE DATE]"
output: html_document
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>


# Exercises and objectives

1) Estimate bias and variance based on a true underlying function  
2) Fitting training data and applying it to test sets with and without regularization

# EXERCISE 1 - Estimate bias and variance based on a true underlying function  

We can express regression as $y = f(x) + \epsilon$ with $E[\epsilon] = 0$ and $var(\epsilon) = \sigma^2$ ($E$ means expected value)  
  
For a given point: $x_0$, we can decompose the expected prediction error , $E[(y_0 - \hat{f}(x_0))^2]$ into three parts - __bias__, __variance__ and __irreducible error__ (the first two together are the __reducible error__):

The expected prediction error is, which we also call the __Mean Squared Error__:  
$E[(y_0 - \hat{f}(x_0))^2] =  bias(\hat{f}(x_0))^2 + var(\hat{f}(x_0)) + \sigma^2$
  
where __bias__ is;
  
$bias(\hat{f}(x_0)) = E[\hat{f}(x_0)] - f(x_0)$

1) Create a function, $f(x)$ that squares its input. This is our __true__ function  
    i. generate data, $y$, based on an input range of [0, 6] with a spacing of 0.1. Call this $x$
    ii. add normally distributed noise to $y$ with $\sigma=5$ (set a seed to 7 `np.random.seed(7)`) to $y$ and call it $y_{noisy}$
    iii. plot the true function and the generated points  
2) Fit a linear regression using `LinearRegression` from `sklearn.linear_model` based on $y_{noisy}$ and $x$ (see code chunk below associated with Exercise 1.2)  
    i. plot the fitted line (see the `.intercept_` and `.coef_` attributes of the `regressor` object) on top of the plot (from 1.1.iii)
    ii. now run the code chunk below associated with Exercise 1.2.ii - what does X_quadratic amount to?
    iii. do a quadratic and a fifth order fit as well and plot them (on top of the plot from 1.2.i)
3) Simulate 100 samples, each with sample size `len(x)` with $\sigma=5$ normally distributed noise added on top of the true function  
    i. do linear, quadratic and fifth-order fits for each of the 100 samples  
    ii create a __new__ figure, `plt.figure`, and plot the linear and the quadratic fits (colour them appropriately); highlight the true value for $x_0=3$. From the graphics alone, judge which fit has the highest bias and which has the highest variance  
    iii. create a __new__ figure, `plt.figure`, and plot the quadratic and the fifth-order fits (colour them appropriately); highlight the true value for $x_0=3$. From the graphics alone, judge which fit has the highest bias and which has the highest variance  
    iv. estimate the __bias__ and __variance__ at $x_0$ for the linear, the quadratic and the fifth-order fits (the expected value $E[\hat{f}(x_0)] - f(x_0)$ is found by taking the mean of all the simulated, $\hat{f}(x_0)$, differences)  
    v. show how the __squared bias__ and the __variance__ is related to the complexity of the fitted models  
    vi. simulate __epsilon__: `epsilon = np.random.normal(scale=5, size=100)`. Based on your simulated values of __bias, variance and epsilon__, what is the __Mean Squared Error__ for each of the three fits? Which fit is better according to this measure? 

    
```{python, eval=FALSE}
# Exercise 1.2
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit() ## what goes in here?
```    

```{python, eval=FALSE}
# Exercise 1.2.ii
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
quadratic = PolynomialFeatures(degree=2)
X_quadratic = quadratic.fit_transform(x.reshape(-1, 1))
regressor = LinearRegression()
regressor.fit() # what goes in here?
y_quadratic_hat # calculate this

```

1) Create a function, $f(x)$ that squares its input. This is our __true__ function  
    i. generate data, $y$, based on an input range of [0, 6] with a spacing of 0.1. Call this $x$
    ii. add normally distributed noise to $y$ with $\sigma=5$ (set a seed to 7 `np.random.seed(7)`) to $y$ and call it $y_{noisy}$
    iii. plot the true function and the generated points  
__SOLUTION 1.1__

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

# 1.1
def square(x):
    return(x**2)

# 1.1.i
x = np.arange(0, 6.1, 0.1) # "to but not including" in python
y_true = square(x) # The true relationship is f(x) = x^2

# 1.1.ii
np.random.seed(7)
noise = np.random.normal(scale=5, size=len(y_true)) # Generate noise
y_noise = y_true + noise # Add noise to true labels

# 1.1.ii
plt.figure() # Initialize new plot
plt.plot(x, y_noise, 'bo')
plt.plot(x, y_true, 'r-')
plt.legend(['noisy_data', 'true'])
plt.show()
```

2) Fit a linear regression using `LinearRegression` from `sklearn.linear_model` based on $y_{noisy}$ and $x$ (see code chunk below associated with Exercise 1.2)  
    i. plot the fitted line (see the `.intercept_` and `.coef_` attributes of the `regressor` object) on top of the plot (from 1.1.iii)
    ii. now run the code chunk below associated with Exercise 1.2.ii - what does X_quadratic amount to?
    iii. do a quadratic and a fifth order fit as well and plot them (on top of the plot from 1.2.i)

__SOLUTION 1.2__

```{python}
# Exercise 1.2
from sklearn.linear_model import LinearRegression
regressor = LinearRegression() # Initialize a regressor (a class instantiation/class object)
x = x.reshape(-1, 1) # X variable has to match in format to sklearn -> each row should be new datapoint, while columns are for each feature of data
regressor.fit(x, y_noise) # Fit model

# 1.2.i
# Extract coefficients (look up sklearn.linear_model, documentation to know how) https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
beta0 = regressor.intercept_
beta1 = regressor.coef_[0]

# Get predictions
y_linear_hat = regressor.predict(x)
# or
y_linear_hat = beta0 + beta1 * x

# Plot predictions on top of previous plot (note that since we're not using a new "plt.figure" it just builds on top)
plt.figure() # Initialize new plot
plt.plot(x, y_noise, 'bo')
plt.plot(x, y_true, 'r-')
plt.plot(x, y_linear_hat, 'g-')
plt.legend(['noisy_data', 'true', 'linear fit'])
plt.show()

# 1.2.ii
from sklearn.preprocessing import PolynomialFeatures
quadratic = PolynomialFeatures(degree=2) # Create an object / class instantiation, that may fit and transform to n-order polynomial x-values
X_quadratic = quadratic.fit_transform(x.reshape(-1, 1)) # From column vector x1, x2 ... xn, to matrix, with 1's in first column, x in second, and x**2

# What does X_quadratic amount to?
# A matrix of column1: 1's, column2: x, column3: x**2. In other words, the x-matrix we worked with last time, which is going to be multiplied into the vector b0, b1, b2

# 1.2.iii
# Train, fit, predict using quadratic
quadratic = PolynomialFeatures(degree=2)
X_quadratic = quadratic.fit_transform(x.reshape(-1, 1)) # transform the X, such that you get a third column of X^2
regressor = LinearRegression()
regressor.fit(X_quadratic, y_noise)
y_quadratic_hat = regressor.intercept_ + regressor.coef_[1] * x + regressor.coef_[2] * x**2

# Plot
plt.figure() # Initialize new plot
plt.plot(x, y_noise, 'bo')
plt.plot(x, y_true, 'r-')
plt.plot(x, y_linear_hat, 'g-')
plt.plot(x, y_quadratic_hat, 'k-')
plt.legend(['noise', 'true', 'linear fit', 'quadratic fit'])
plt.show()

# Train, fit, predict using quintic
fifth = PolynomialFeatures(degree=5)
X_fifth = fifth.fit_transform(x.reshape(-1, 1))
regressor = LinearRegression()
regressor.fit(X_fifth, y_noise)
y_fifth_hat = regressor.intercept_ + regressor.coef_[1] * x + regressor.coef_[2] * x**2 + regressor.coef_[3] * x**3 + regressor.coef_[4] * x**4 + regressor.coef_[5] * x**5

# Plot
plt.figure() # Initialize new plot
plt.plot(x, y_noise, 'bo')
plt.plot(x, y_true, 'r-')
plt.plot(x, y_linear_hat, 'g-')
plt.plot(x, y_quadratic_hat, 'k-')
plt.plot(x, y_fifth_hat, 'y-')
plt.legend(['noise', 'true', 'linear fit', 'quadratic fit', 'fifth order fit'])
plt.show()
```

3) Simulate 100 samples, each with sample size `len(x)` with $\sigma=5$ normally distributed noise added on top of the true function  
    i. do linear, quadratic and fifth-order fits for each of the 100 samples  
    ii create a __new__ figure, `plt.figure`, and plot the linear and the quadratic fits (colour them appropriately); highlight the true value for $x_0=3$. From the graphics alone, judge which fit has the highest bias and which has the highest variance  
    iii. create a __new__ figure, `plt.figure`, and plot the quadratic and the fifth-order fits (colour them appropriately); highlight the true value for $x_0=3$. From the graphics alone, judge which fit has the highest bias and which has the highest variance  
    iv. estimate the __bias__ and __variance__ at $x_0$ for the linear, the quadratic and the fifth-order fits (the expected value $E[\hat{f}(x_0)] - f(x_0)$ is found by taking the mean of all the simulated, $\hat{f}(x_0)$, differences)  
    v. show how the __squared bias__ and the __variance__ is related to the complexity of the fitted models  
    vi. simulate __epsilon__: `epsilon = np.random.normal(scale=5, size=100)`. Based on your simulated values of __bias, variance and epsilon__, what is the __Mean Squared Error__ for each of the three fits? Which fit is better according to this measure? 

__SOLUTION 1.3.__

```{python}
np.random.seed(7) # To get same results

# 2.3
samples = [(np.random.normal(scale=5, size=len(x)) + square(x[:,0])) for i in range(100)] # 100 times, take the true_y (which is x**2), and + it with random vector, with same length, mean of 0 (implicit) and a sd of 5. Append all this to a single list

# Inspect samples. Notice here that I'm using an F-string -> A string object that may take code and print it as string.
print(f"Length of samples: {len(samples)}, \nLength of first element in samples: {len(samples[0])}")
# Inspection of samples 

# 2.3.i
# Initialize PolynomialFeatures objects, and fit_transform X values so that we may train quadratic and quintic models
quadratic = PolynomialFeatures(degree=2) # Create an object / class instantiation, that may fit and transform to n-order polynomial x-values
quintic = PolynomialFeatures(degree=5)

# Transform
X_quadratic = quadratic.fit_transform(x.reshape(-1, 1)) # From column vector x1, x2 ... xn, to matrix, with 1's in first column, x in second, and x**2 in 3rd, etc.
X_quintic = quintic.fit_transform(x.reshape(-1, 1)) 

# Empty list for appending to
lin_preds = []
quad_preds = []
quint_preds = []

# For loop to train models and predict, as well as saving predictions
for i in samples:
  # Linear
  lin_regressor = LinearRegression(fit_intercept=False)
  lin_regressor.fit(x, i)
  lin_preds.append(lin_regressor.predict(x))
  
  # Quadratic
  quad_regressor = LinearRegression(fit_intercept=False)
  quad_regressor.fit(X_quadratic, i)
  quad_preds.append(quad_regressor.predict(X_quadratic))
  
  # Quintic
  quint_regressor = LinearRegression(fit_intercept=False)
  quint_regressor.fit(X_quintic, i)
  quint_preds.append(quint_regressor.predict(X_quintic))

# Plotting linear and quadratic fit
plt.figure()
for i in range(0, len(quad_preds)): # Now that we've learned that you just write it on top, and run lines consecutively, we can just loop over it.
  plt.plot(x, lin_preds[i], "y-")
  plt.plot(x, quad_preds[i], "g-")
plt.plot(3, 3**2, "ro") # Plot x = 3, and the y_true, of this x
plt.legend(["Linear predictions", "Quadratic predictions"]) # Gives legend
plt.show()

# 2.3.ii
# Plotting quadratic and quintic fits
plt.figure()
for i in range(0, len(quad_preds)): # Now that we've learned that you just write it on top, and run lines consecutively, we can just loop over it.
  plt.plot(x, quad_preds[i], "g-")
  plt.plot(x, quint_preds[i], "b-")
plt.plot(3, 3**2, "ro") # Plot x = 3, and the y_true, of this x
plt.legend(["Quadratic predictions", "Quintic predictions"])
plt.show()

# Which models have highest bias, and which have highest variance?
# Linear model highest bias
# Quintic model highest variance

# 2.3.iii
# Get the index with np.where(). As np.where() looks at matrices, we index to get first dimension (row), and not the second dimension
x_highlight = np.where(x == 3)[0]

# For each of the prediction vectors for the linear models (one vector for each model), look up the value at the index where x = 3. Put this into a list.
# Take the mean of this, so we get the average prediction. Minus with the actual value, so we get the average residual value.
bias_lin = np.mean([i[x_highlight] for i in lin_preds]) - 3**2 
bias_quad = np.mean([i[x_highlight] for i in quad_preds]) - 3**2
bias_quint = np.mean([i[x_highlight] for i in quint_preds]) - 3**2 

# For each of the prediction vectors of the linear models (100 vectors), find look up the value at the index where x = 3. Take all these values into a list
# Then find variance of this list
var_lin = np.var([i[x_highlight] for i in lin_preds])
var_quad = np.var([i[x_highlight] for i in quad_preds])
var_quint = np.var([i[x_highlight] for i in quint_preds])

# 2.3.iv
# Inspect
bias_lin # Large residuals (large bias)
bias_quad # Small residuals (lower bias)
bias_quint # Smallest residuals (lowest bias)
var_lin # Low variance (the predictions for x = 3, are similar across linear models)
var_quad # Higher variance (the predictions for x = 3, are different across models)
var_quint # Highest variance (the predictions for x = 3, are very different across models)

# 2.3.v
# Define Epsilon as Lau says
epsilon = np.random.normal(scale=5, size=100)

# Calculate MSE using formula
MSE_lin = bias_lin**2 + var_lin + np.var(epsilon)
MSE_quad = bias_quad**2 + var_quad + np.var(epsilon)
MSE_quint = bias_quint**2 + var_quint + np.var(epsilon)

# Inspect, to see MSE
# Highest for linear models, same for quad and quint models
MSE_lin
MSE_quad
MSE_quint
```

# EXERCISE 2: Fitting training data and applying it to test sets with and without regularization

All references to pages are made to this book:
Raschka, S., 2015. Python Machine Learning. Packt Publishing Ltd.  

1) Import the housing dataset using the upper chunk of code from p. 280 
    i. and define the correlation matrix `cm` as done on p. 284  
    ii. based on this matrix, do you expect collinearity can be an issue if we run multiple linear regression  by fitting MEDV on LSTAT, INDUS, NOX and RM?

__SOLUTION 2.1__

``` {python}
# 2.1
import pandas as pd
import numpy as np

# Read csv
df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data', header=None, sep='\s+')

# Give columns names
df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',
              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']

# Which columns are we interested in?
cols = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']

#2.1. i
cm = np.corrcoef(df[cols].values.T) # Get correlation  matrix.

# 2.1.ii
# Is the correlation a problem?
# Yes. Many predictors correlate highly ( < 60)
```

2) Fit MEDV on  LSTAT, INDUS, NOX and RM (standardize all five variables by using `StandardScaler.fit_transform`, (`from sklearn.preprocessing import StandardScaler`) by doing multiple linear regression using `LinearRegressionGD` as defined on pp. 285-286
    i. how much does the solution improve in terms of the cost function if you go through 40 iterations instead of the default of 20 iterations?  
    ii. how does the residual sum of squares based on the analytic solution (Ordinary Least Squares) compare to the cost after 40 iterations?
    iii. Bonus question: how many iterations do you need before the Ordinary Least Squares and the Gradient Descent solutions result in numerically identical residual sums of squares?  

__SOLUTION 2.2__

```{python}
# 2.2 
# Get X and y
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X = ss.fit_transform(df[cols[0:-1]].values) # Get X, standardized
y = df[cols[-1]].values # Get y
y = y.reshape(-1, 1)
y = ss.fit_transform(y) # Standardize (Redundant? They do it in book)
y = y.reshape(-1) # Input format

# Define class as in book
class LinearRegressionGD(object):
    
    def __init__(self, eta=0.001, n_iter=20):
        self.eta = eta ## learning rate
        self.n_iter = n_iter
        
    def fit(self, X, y):
        self.w_ = np.zeros(1 + X.shape[1]) # out predictor variables
        self.cost_ = []
        
        for i in range(self.n_iter):
            output = self.net_input(X) # our linear predictor X@Beta
            errors = (y - output)
            self.w_[1:] += self.eta * X.T.dot(errors)
            self.w_[0] += self.eta * errors.sum()
            cost = (errors**2).sum() / 2.0
            self.cost_.append(cost)
        return self
    
    def net_input(self, X):
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    def predict(self, X):
        return self.net_input(X)

LR = LinearRegressionGD(n_iter = 40) # Initialize class object

LR.fit(X, y) # Fit model

# 2.2.i
cost_20 = LR.cost_[19] # Get cost at iteration 20, and 40 (indexed differently)
cost_40 = LR.cost_[39]
print(cost_20 - cost_40) # improvement


# 2.2.ii
# Get cost of OLS method
beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y
y_hat = X @ beta_hat
RSS = np.sum((y - y_hat)**2)

# Compared the two
print(cost_40 - RSS/2)


# 2.2.ii

## found by trial and error - you could write a function that loops until it numerically becomes 0
LR.n_iter = 201
LR.fit(X, y)
print(LR.cost_[-1] - RSS/2)

``` 

3) Build your own cross-validator function. This function should randomly split the data into $k$ equally sized folds (see figure p. 176) (see the code chunk associated with exercise 2.3). It should also return the Mean Squared Error for each of the folds
    i. Cross-validate the fits of your model from Exercise 2.2. Run 11 folds and run 500 iterations for each fit  
    ii. What is the mean of the mean squared errors over all 11 folds?  

__SOLUTION 2.3__

```{python}
# Define function with certain input
def cross_validation(model, X, y, k):
  mses = []
  fold_size = y.shape[0] // k # Get the size of the folds (use // to have integer division)
  for fold in range(k): # For each fold
    test_index_start = fold * fold_size
    test_index_stop = (fold + 1) * fold_size
    test_indices = np.arange(test_index_start, test_index_stop)
    train_indices = [i for i in np.arange(len(y)) if i not in test_indices]
    
    model.fit(X[train_indices], y[train_indices])
    y_test_hat = model.predict(X[test_indices])
    mse = np.mean((y[test_indices] - y_test_hat)**2)
    mses.append(mse)
  
  return np.mean(mses)

LR = LinearRegressionGD(n_iter=500)
mse = cross_validation(LR, X, y, 11)
print(mse)
```

4) Now, we will do a Ridge Regression. Use `Ridge` (see code chunk associated with Exercise 2.4) to find the optimal `alpha` parameter ($\lambda$)
    i. Find the _MSE_ (the mean of the _MSE's_ associated each fold) associated with a reasonable range of `alpha` values (you need to find the minimum)  
    ii. Plot the _MSE_ as a function of `alpha` ($\lambda$). Make sure to include an _MSE_ for `alpha=0` as well  
    iii. Find the _MSE_ for the optimal `alpha`, compare its _MSE_ to that of the OLS regression
    iv. Do the same steps for Lasso Regression `Lasso`  
    v. Describe the differences between these three models, (the optimal Lasso, the optimal Ridge and the OL)

```{python, eval=FALSE}
# Exercise 2.4
from sklearn.linear_model import Ridge, Lasso
RR = Ridge(alpha=?)
LassoR = Lasso(alpha)

```

__SOLUTION 2.4 (up until 2.4.iv)__

```{python, eval=FALSE}
from sklearn.linear_model import Ridge, Lasso
import numpy as np

# 2.4.i
# Define lambda grid
lambda_grid = np.arange(0.1, 100, 0.1)

# Get mses of fitted models in range of lambdas
mses = []
for l in lambda_grid:
  RR = Ridge(alpha = l)
  mse = cross_validation(RR, X, y, 11)
  mses.append(mse)

# 2.4.ii
plt.figure()
plt.plot(lambda_grid, mses)
plt.show()

# 2.4.iii
# Find optimal lambda value (optional)
optimal_lambda_index = mses.index(min(mses))
optimal_lambda = lambda_grid[optimal_lambda_index]
optimal_lambda

# Find MSE for optimal lambda value
min(mses)
# Find MSE for lambda = 0 (same as linear regression without ridge)
mses[0]

# MSE = 0.438 for lambda value 42.6
# MSE = 0.440 for lambda = 0
```

__SOLUTION 2.4.iv)__

```{python}
from sklearn.linear_model import Ridge, Lasso
# 2.4.iv
# 2.4.i
# Define lambda grid
lambda_grid = np.arange(0.0001, 0.1, 0.0001)

# Get mses of fitted models in range of lambdas
mses = []
for l in lambda_grid:
  RR = Lasso(alpha = l)
  mse = cross_validation(RR, X, y, 11)
  mses.append(mse)

# 2.4.ii
plt.figure()
plt.plot(lambda_grid, mses)
plt.show()

# 2.4.iii
# Find optimal lambda value (optional)
optimal_lambda_index = mses.index(min(mses))
optimal_lambda = lambda_grid[optimal_lambda_index]
optimal_lambda

# Find MSE for optimal lambda value
min(mses)
# Find MSE for lambda = 0 (same as linear regression without ridge)
mses[0]

# At lambda = 0.0161, MSE = 0.4346
# At lambda = 0, MSE = 0.440

```

__SOLUTION 2.4.v)__

```{python}
# 2.4.v
# It seems that Ridge and Lasso outperforms non-regularized solution. But only ever so slightly.
# Ridge seems to outperform Lasso.
# ElasticNet would likely be most optimal.

```
