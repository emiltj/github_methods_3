two_d.var()
two_d.var()
two_d.var()
from sklearn import MinMaxScaler
reticulate::repl_python()
what_we_want = data[1, :, :] @ data[1, :, :].T
import numpy as np
import matplotlib.pyplot as plt
data = np.load(os.path.join("data", "megmag_data.npy"))
np.random.seed(1)
data.shape
# 682 repetitions (trials)
# 102 n_sensors
# 251 time points
# Make a range of numbers, from -200 to 801, with increments of 4
times = np.arange(-200, 801, 4)
# See that it fits with 251 time points
len(times) == data.shape[2]
# Why is this a sensor covariance matrix? What is happening here
# If we take data from 1 trial, we get shape 102, 251.
data[1, :, :].shape # 102 is sensors, so that is the shape that we want.
# Matrix multiplication of matrices 5x2 @ 2x5 result in 5x5
# Since we want a 102x102 output matrix, we need to use
what_we_want = data[1, :, :] @ data[1, :, :].T
what_we_want.shape
####### Just explanation
# Correlation vs covariance
# Correlation values are standardized (1 means perfect correlation, in correlation matrix)
# Covariance aren't
# Define N (from formula)
N = data.shape[0]
# For each trial, multiply the matrix with itself (one of them transposed) as in formula. Append to list
matrices = []
for trial in np.arange(N):
matrix = data[trial, :, :] @ data[trial, :, :].T
matrices.append(matrix)
# Compute covariance matrix (just using the formula provided by Lau)
cov_matrix = (1/N)*sum(matrices)
# Plot covariance matrix
plt.figure()
plt.imshow(cov_matrix, vmin=-5e-23, vmax=5e-23)
plt.colorbar()
plt.show()
average = np.mean(data, axis=0)
# Before we had a score per trial, per sensor, per time.
# Now we have an average score (across trials) per sensor, per time.
#Check that first dimension is time and that the second is sensor (as Lau states)
average.shape
# It is not the case, so we may transpose
average = average.T
plt.figure()
plt.plot(times, average)
plt.axvline(color='k')
plt.axhline(color='k')
plt.show()
# Now we can see the average microvolt over time, for each sensor
# Find max value
max_value = np.max(average)
# Get index of max value
max_time_idx, max_sensor_idx = np.where(average == max_value)
# Check that you have found it
average[max_time_idx, max_sensor_idx] == max_value
max_time_idx
max_sensor_idx
# The max value is found in sensor with index 73, at time point with index 112
# Check which dimension had sensors
data.shape
# Initialize plot
plt.figure()
plt.plot(times, data[:, int(max_sensor_idx), :].T) # Take the data, but only for the sensor 73
# Transpose the data matrix, to have the 3rd dimension (time) as the first dimension, to match "times".
plt.axvline(color='k')
plt.axhline(color='k')
plt.axvline(x=times[max_time_idx], linestyle='--', color='k') # Plot a line at the timepoint with largest value
plt.show()
# We end up with a plot showing the Tesla over time for sensor 73. Each line represents a different trial.
# Each of the single trials contain signal + noise. Since the noise is random, we can signal it out by averaging across trials.
quit
# Each of the single trials contain signal + noise. Since the noise is random, we can signal it out by averaging across trials.
1.2. Now load `pas_vector.npy` (call it `y`). PAS is the same as in Assignment 2, describing the clarity of the subjective experience the subject reported after seeing the briefly presented stimulus
```{python}
y = np.load(os.path.join("data", "pas_vector.npy"))
```
reticulate::repl_python()
y = np.load(os.path.join("data", "pas_vector.npy"))
data.shape
len(y)
# Trials and y have same length
# Get all unique PAS ratings
PAS = np.unique(y)
avgs = [] # Initialize empty list for appending to
for i in PAS:
data_subset = data[y == i, :, :] # Take all data, but only for trials that were rated as 1, 2, 3, 4 (for each loop) in PAS.
avg = np.mean(data_subset, axis = 0) # Take mean across all sensors and timepoints
avgs.append(avg) # Append to list
plt.figure()
# For each of the 4 PAS-rating subset, averages. Plot times on the x-axis, and the average (but only for sensor 73) on the y-axis
for avg in avgs:
plt.plot(times, avg[int(max_sensor_idx), :])
plt.axhline(color='k')
plt.axvline(color='k')
plt.legend(PAS)
plt.show()
# Didn't expect anything. We see that P2 has largest P1 and second largest N1.
# Perhaps larger activity when analyzing harder. PAS 1 = Too hard to try and process what we saw. PAS 3, 4, too easy? Hard to know
quit
# EXERCISE 2 - Do logistic regression to classify pairs of PAS-ratings
reticulate::repl_python()
# Subset
data_1_2 = data[y < 3, :, :]
y_1_2 = y[y < 3]
data_1_2.shape
X_1_2 = data_1_2.reshape(214, -1)
X_1_2.shape
# It is just flattening the array / Concatenating the values as shown below:
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_1_2 = sc.fit_transform(X_1_2)
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(penalty='none')
lr.fit(X_1_2, y_1_2)
# Calculate correct/incorrect (this function predicts using X_1_2 and compares predictions to y_1_2)
lr.score(X_1_2, y_1_2)
# Yes. Too good performance
lr_l1 = LogisticRegression(penalty='l1', solver='liblinear')
lr_l1.fit(X_1_2, y_1_2)
# Flatten the array of coefficients to 1d array
coefs = lr_l1.coef_.flatten()
len([coef for coef in coefs if coef != 0])
# 282
# Create list of [False, False, True, False, True], to know which predictor variables to exclude
non_zero_indices = coefs != 0
# Figure out shape
X_1_2.shape
# Subset to only include predictor variables that have non-zero beta values
X_1_2_reduced = X_1_2[:,non_zero_indices]
####### Just explanation
# Why is this a feature covariance matrix? What is happening here
X_1_2_reduced.shape # We can see that the first dimension is features
X_1_2_reduced.shape # We can see that the second dimension is features
(X_1_2_reduced.T @ X_1_2_reduced).shape
reticulate::repl_python()
import numpy as np
import matplotlib.pyplot as plt
data = np.load(os.path.join("data", "megmag_data.npy"))
np.random.seed(1)
data.shape
# Make a range of numbers, from -200 to 801, with increments of 4
times = np.arange(-200, 801, 4)
# See that it fits with 251 time points
len(times) == data.shape[2]
####### Just explanation
# Why is this a sensor covariance matrix? What is happening here
# If we take data from 1 trial, we get shape 102, 251.
data[1, :, :].shape # 102 is sensors, so that is the shape that we want.
# Matrix multiplication of matrices 5x2 @ 2x5 result in 5x5
# Since we want a 102x102 output matrix, we need to use
what_we_want = data[1, :, :] @ data[1, :, :].T
what_we_want.shape
####### Just explanation
# Correlation vs covariance
# Correlation values are standardized (1 means perfect correlation, in correlation matrix)
# Covariance aren't
# Define N (from formula)
N = data.shape[0]
# For each trial, multiply the matrix with itself (one of them transposed) as in formula. Append to list
matrices = []
for trial in np.arange(N):
matrix = data[trial, :, :] @ data[trial, :, :].T
matrices.append(matrix)
# Compute covariance matrix (just using the formula provided by Lau)
cov_matrix = (1/N)*sum(matrices)
# Plot covariance matrix
plt.figure()
plt.imshow(cov_matrix, vmin=-5e-23, vmax=5e-23)
plt.colorbar()
plt.show()
# No they don't
# Take averages along the 0th axis (trials)
average = np.mean(data, axis=0)
# Before we had a score per trial, per sensor, per time.
# Now we have an average score (across trials) per sensor, per time.
#Check that first dimension is time and that the second is sensor (as Lau states)
average.shape
# It is not the case, so we may transpose
average = average.T
plt.figure()
plt.plot(times, average)
plt.axvline(color='k')
plt.axhline(color='k')
plt.show()
# Now we can see the average microvolt over time, for each sensor
quit
reticulate::repl_python()
max_value = np.max(average)
# Get index of max value
max_time_idx, max_sensor_idx = np.where(average == max_value)
# Check that you have found it
average[max_time_idx, max_sensor_idx] == max_value
max_time_idx
max_sensor_idx
# The max value is found in sensor with index 73, at time point with index 112
# Check which dimension had sensors
data.shape
# Initialize plot
plt.figure()
plt.plot(times, data[:, int(max_sensor_idx), :].T) # Take the data, but only for the sensor 73
# Transpose the data matrix, to have the 3rd dimension (time) as the first dimension, to match "times".
plt.axvline(color='k')
plt.axhline(color='k')
plt.axvline(x=times[max_time_idx], linestyle='--', color='k') # Plot a line at the timepoint with largest value
plt.show()
# We end up with a plot showing the Tesla over time for sensor 73. Each line represents a different trial.
# Each of the single trials contain signal + noise. Since the noise is random, we can signal it out by averaging across trials.
quit
# Each of the single trials contain signal + noise. Since the noise is random, we can signal it out by averaging across trials.
1.2. Now load `pas_vector.npy` (call it `y`). PAS is the same as in Assignment 2, describing the clarity of the subjective experience the subject reported after seeing the briefly presented stimulus
```{python}
y = np.load(os.path.join("data", "pas_vector.npy"))
```
1.2.i. Which dimension in the `data` array does it have the same length as?
```{python}
data.shape
len(y)
reticulate::repl_python()
y = np.load(os.path.join("data", "pas_vector.npy"))
data.shape
len(y)
# Get all unique PAS ratings
PAS = np.unique(y)
avgs = [] # Initialize empty list for appending to
for i in PAS:
data_subset = data[y == i, :, :] # Take all data, but only for trials that were rated as 1, 2, 3, 4 (for each loop) in PAS.
avg = np.mean(data_subset, axis = 0) # Take mean across all sensors and timepoints
avgs.append(avg) # Append to list
plt.figure()
# For each of the 4 PAS-rating subset, averages. Plot times on the x-axis, and the average (but only for sensor 73) on the y-axis
for avg in avgs:
plt.plot(times, avg[int(max_sensor_idx), :])
plt.axhline(color='k')
plt.axvline(color='k')
plt.legend(PAS)
plt.show()
# Didn't expect anything. We see that P2 has largest P1 and second largest N1.
# Perhaps larger activity when analyzing harder. PAS 1 = Too hard to try and process what we saw. PAS 3, 4, too easy? Hard to know
# Subset
data_1_2 = data[y < 3, :, :]
y_1_2 = y[y < 3]
data_1_2.shape
X_1_2 = data_1_2.reshape(214, -1)
X_1_2.shape
# It is just flattening the array / Concatenating the values as shown below:
# So that we get [s1t1, s1t2, s1t3 ... s102t251]
# Before we had a score per trial, per sensor, per time.
# Now we, for each trial have: [sensor1timepoint1, s1t2, s1t3 ... s102t251]
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_1_2 = sc.fit_transform(X_1_2)
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(penalty='none')
lr.fit(X_1_2, y_1_2)
# Calculate correct/incorrect (this function predicts using X_1_2 and compares predictions to y_1_2)
lr.score(X_1_2, y_1_2)
# Yes. Too good performance
lr_l1 = LogisticRegression(penalty='l1', solver='liblinear')
lr_l1.fit(X_1_2, y_1_2)
# Flatten the array of coefficients to 1d array
coefs = lr_l1.coef_.flatten()
len([coef for coef in coefs if coef != 0])
# Create list of [False, False, True, False, True], to know which predictor variables to exclude
non_zero_indices = coefs != 0
# Figure out shape
X_1_2.shape
# Subset to only include predictor variables that have non-zero beta values
X_1_2_reduced = X_1_2[:,non_zero_indices]
####### Just explanation
# Why is this a feature covariance matrix? What is happening here
X_1_2_reduced.shape # We can see that the second dimension is features (282)
# Matrix multiplication of matrices 5x2 @ 2x5 result in 5x5
# Since we want a 282x282 output matrix, we need to use
(X_1_2_reduced.T @ X_1_2_reduced).shape
# Correlation vs covariance
# Correlation values are standardized (1 means perfect correlation, in correlation matrix)
# Covariance aren't
###### Just explanation
# Covariance matrix
cov_matrix_reduced = X_1_2_reduced.T @ X_1_2_reduced
# Plot covariance matrix
plt.figure()
plt.imshow(cov_matrix_reduced)#, vmin=-5e-23, vmax=5e-23)
plt.colorbar()
plt.show()
from sklearn.model_selection import cross_val_score, StratifiedKFold
# Check to see if there is an equal number
sum(y_1_2 == 1) == sum(y_1_2 == 2) # There isn't
# Define function (just using Laus)
def equalize_targets_binary(data, y):
np.random.seed(7)
targets = np.unique(y)
if len(targets) > 2:
raise NameError("can't have more than two targets")
counts = list()
indices = list()
for target in targets:
counts.append(np.sum(y == target))
indices.append(np.where(y == target)[0])
min_count = np.min(counts)
first_choice = np.random.choice(indices[0], size=min_count, replace=False)
second_choice = np.random.choice(indices[1], size=min_count, replace=False)
new_indices = np.concatenate((first_choice, second_choice))
new_y = y[new_indices]
new_data = data[new_indices, :, :]
return new_data, new_y
# Utilize function to get data with equal number of samples with each PAS target (1, and 2)
data_1_2_equal, y_1_2_equal = equalize_targets_binary(data_1_2, y_1_2)
# Collapse into 2 dimensions again
X_1_2_equal = data_1_2_equal.reshape(data_1_2_equal.shape[0], -1)
# Scale features
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_1_2_equal = sc.fit_transform(X_1_2_equal)
# Check to see whether there now are fewer trials
X_1_2_equal.shape # Fewer trials than before
lr = LogisticRegression()
cv = StratifiedKFold(n_splits = 5)
scores = cross_val_score(lr, X_1_2_equal, y_1_2_equal, cv=cv)
# Average performance
np.mean(scores)
# Define Cs as Lau has done
Cs = [1e5, 1e1, 1e-5]
# “C = Inverse of regularization strength; must be a positive float.”
# Fit new models
accs = []
for C in Cs:
lr = LogisticRegression(penalty='l2', C=C)
acc = np.mean(cross_val_score(lr, X_1_2_equal, y_1_2_equal, cv=cv))
accs.append(acc)
accs
# Find best scoring
np.max(accs) * len(y_1_2_equal) # Average number of correct across folds in best model
np.mean(accs) * len(y_1_2_equal) # Average number of correct across folds across models
# Best model on average predicts 8 more correct than when comparing to average
# "Find" best C (or just look above)
best_c = Cs[np.argmax(accs)]
# Go back and find data with only PAS 1 and 2.
data_1_2.shape
# Equalize data, so there is an equal number of each PAS class
data_1_2_equal, y_1_2_equal = equalize_targets_binary(data_1_2, y_1_2)
# Initialize LogisticRegression, StratifiedKFold and Scaler objects
lr = LogisticRegression(penalty='l2', C=best_c)
cv = StratifiedKFold(n_splits = 5)
sc = StandardScaler()
# Empty list for appending to
accs = []
# For each time index
for i in np.arange(251):
d = data_1_2_equal[:,:,i] # Get subset with only the data from time i
# Scale data
d = sc.fit_transform(d) # Scale data
# Get accuracy from cross-validation
acc = np.mean(cross_val_score(lr, d, y_1_2_equal, cv=cv)) # Find mean performance across folds
# Append to the empty list
accs.append(acc)
# Plot performance over time
plt.figure()
plt.plot(times, accs)
plt.ylim(0.40, 0.70)
plt.axhline(color='k', y=0.50)
plt.axvline(color='k')
plt.show()
best_time = times[np.argmax(accs)]
best_time
# Go back and find data with only PAS 1 and 2.
data_1_2.shape
# Equalize data, so there is an equal number of each PAS class
data_1_2_equal, y_1_2_equal = equalize_targets_binary(data_1_2, y_1_2)
# Initialize LogisticRegression, StratifiedKFold and Scaler objects
lr = LogisticRegression(penalty='l1', C=1e-1, solver='liblinear')
cv = StratifiedKFold(n_splits = 5)
sc = StandardScaler()
# Empty list for appending to
accs_l1 = []
# For each time index
for i in np.arange(251):
d = data_1_2_equal[:,:,i] # Get subset with only the data from time i
d = sc.fit_transform(d) # Scale data
acc = np.mean(cross_val_score(lr, d, y_1_2_equal, cv=cv)) # Find mean performance across folds
accs_l1.append(acc)
# Plot performance over time
plt.figure()
plt.plot(times, accs, "-r")
plt.plot(times, accs_l1, "-g")
plt.ylim(0.40, 0.70)
plt.axhline(color='k', y=0.50)
plt.axvline(color='k')
plt.legend(['no penalty', "l1 penalty"])
plt.show()
best_time = times[np.argmax(accs_l1)]
best_time
indices = []
for i in y:
if i == 1 or i == 4:
indices.append(True)
else:
indices.append(False)
# Subset using the indices (now only trials with 1 or 4)
data_1_4 = data[indices, :, :]
y_1_4 = y[indices]
# The exact same code as before, but now with this data instead
data_1_4_equal, y_1_4_equal = equalize_targets_binary(data_1_4, y_1_4)
# Initialize LogisticRegression, StratifiedKFold and Scaler objects
lr = LogisticRegression(penalty='l1', C=1e-1, solver='liblinear')
cv = StratifiedKFold(n_splits = 5)
sc = StandardScaler()
# Empty list for appending to
accs_l1_1_4 = []
# Subset data to only get data from each timepoint
for i in np.arange(251):
d = data_1_4_equal[:,:,i] # Get subset with only the data from time i
d = sc.fit_transform(d) # Scale data
acc = np.mean(cross_val_score(lr, d, y_1_4_equal, cv=cv)) # Find mean performance across folds
accs_l1_1_4.append(acc)
# Plot performance over time
plt.figure()
plt.plot(times, accs_l1, "-r")
#plt.plot(times, accs_l1_1_4, "-g")
plt.ylim(0.40, 0.70)
plt.axhline(color='k', y=0.50)
plt.axvline(color='k')
plt.legend(['1_2', "1_4"])
plt.show()
best_time = times[np.argmax(accs_l1_1_4)]
best_time
# Chance is at 50%
def equalize_targets(data, y):
np.random.seed(7)
targets = np.unique(y)
counts = list()
indices = list()
for target in targets:
counts.append(np.sum(y == target))
indices.append(np.where(y == target)[0])
min_count = np.min(counts)
first_choice = np.random.choice(indices[0], size=min_count, replace=False)
second_choice = np.random.choice(indices[1], size=min_count, replace=False)
third_choice = np.random.choice(indices[2], size=min_count, replace=False)
fourth_choice = np.random.choice(indices[3], size=min_count, replace=False)
new_indices = np.concatenate((first_choice, second_choice,
third_choice, fourth_choice))
new_y = y[new_indices]
new_data = data[new_indices, :, :]
return new_data, new_y
# Load data in again (can't remember if I changed it a long the way)
data = np.load(os.path.join("data", "megmag_data.npy"))
y = np.load(os.path.join("data", "pas_vector.npy"))
# Using function to have same number of trials with each PAS rating
data_equalized, y = equalize_targets(data, y)
data_equalized.shape[0]
# Collapse the 3 dim into 2
X = data_equalized.reshape(data_equalized.shape[0], -1)
# Before we had a score per trial, per sensor, per time.
sc = StandardScaler()
X = sc.fit_transform(X)
# Import SVC class
from sklearn.svm import SVC
# Define new class object
svm_linear = SVC(kernel='linear', C=1)
svm_radial = SVC(kernel='rbf', C=1)
# Initalize a StratifiedKFold class object
cv = StratifiedKFold()
# Perform cross-validation
cv_score_lin = cross_val_score(svm_linear, X, y, cv=cv)
cv_score_rad = cross_val_score(svm_radial, X, y, cv=cv)
np.mean(cv_score_lin)
np.mean(cv_score_rad)
data_equalized.shape
accs = []
# For each timepoint
for i in np.arange(251):
d = data_equalized[:,:,i] # Get subset with only the data from time i
d = sc.fit_transform(d) # Scale data
acc = np.mean(cross_val_score(svm_radial, d, y, cv=cv)) # Find mean performance across folds
accs.append(acc)
# Plot performance over time
plt.figure()
plt.plot(times, accs)
#plt.ylim(0.0, 0.50)
plt.axhline(color='k', y=0.25)
plt.axvline(color='k')
plt.show()
# baseline accuracy would be at 25%
from sklearn.model_selection import train_test_split
data_equalized_2d = data_equalized.reshape([data_equalized.shape[0], -1])
# Before we had a score per trial, per sensor, per time.
# Now we, for each trial have: [sensor1timepoint1, s1t2, s1t3 ... s102t251]
# In other words a 2D matrix
X_train, X_test, y_train, y_test = train_test_split(data_equalized_2d, y)
# Scale data first
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
# Define classifier, and fit + predict
svm_radial = SVC(kernel='rbf', C=1)
svm_radial.fit(X_train, y_train)
predictions = svm_radial.predict(X_test)
#### Lau.
# I'm not getting the same predictions as you
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
conf_matrix = confusion_matrix(y_test, predictions, labels=svm_radial.classes_) # True class is rows, predicted class is columns
# Plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=svm_radial.classes_)
disp.plot()
plt.show()
